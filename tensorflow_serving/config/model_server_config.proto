syntax = "proto3";

package tensorflow.serving;
option cc_enable_arenas = true;

import "google/protobuf/any.proto";

// Common configuration for loading a model being served.
message ModelConfig {
  // Name of the model.
  string name = 1;

  // Base path to the model, excluding the version directory.
  // E.g> for a model at /foo/bar/my_model/123, where 123 is the version, the
  // base path is /foo/bar/my_model.
  string base_path = 2;

  // Type of model (e.g. "tensorflow").
  string model_type = 3;
}

// Static list of models to be loaded for serving.
message ModelConfigList {
  repeated ModelConfig config = 1;
}

// ModelServer config.
message ModelServerConfig {

  // ModelServer takes either a static file-based model config list or an Any
  // proto representing custom model config that is loaded dynamically at
  // runtime (through network RPC, custom service, etc.).
  oneof config {
    ModelConfigList model_config_list = 1;
    google.protobuf.Any dynamic_model_config = 2;
  }
}