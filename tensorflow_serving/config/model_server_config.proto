syntax = "proto3";

package tensorflow.serving;
option cc_enable_arenas = true;

import "google/protobuf/any.proto";
import "tensorflow_serving/config/logging_config.proto";
import "tensorflow_serving/sources/storage_path/file_system_storage_path_source.proto";

// The type of model.
// TODO(b/31336131): DEPRECATED.
enum ModelType {
  MODEL_TYPE_UNSPECIFIED = 0 [deprecated = true];
  TENSORFLOW = 1 [deprecated = true];
  OTHER = 2 [deprecated = true];
};

// Common configuration for loading a model being served.
message ModelConfig {
  // Name of the model.
  string name = 1;

  // Base path to the model, excluding the version directory.
  // E.g> for a model at /foo/bar/my_model/123, where 123 is the version, the
  // base path is /foo/bar/my_model.
  string base_path = 2;

  // Type of model.
  // TODO(b/31336131): DEPRECATED. Please use 'model_platform' instead.
  ModelType model_type = 3 [deprecated = true];

  // Type of model (e.g. "tensorflow").
  string model_platform = 4;

  // Version policy for the model indicating how many versions of the model to
  // be served at the same time.
  // The default option is to serve only the latest version of the model.
  FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;

  // Configures logging requests and responses, to the model.
  LoggingConfig logging_config = 6;
}

// Static list of models to be loaded for serving.
message ModelConfigList {
  repeated ModelConfig config = 1;
}

// ModelServer config.
message ModelServerConfig {
  // ModelServer takes either a static file-based model config list or an Any
  // proto representing custom model config that is fetched dynamically at
  // runtime (through network RPC, custom service, etc.).
  oneof config {
    ModelConfigList model_config_list = 1;
    google.protobuf.Any custom_model_config = 2;
  }
}
