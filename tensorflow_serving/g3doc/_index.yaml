book_path: /serving/_book.yaml
project_path: /serving/_project.yaml
description: <!--no description-->
landing_page:
  custom_css_path: /site-assets/css/style.css
  rows:
  - heading: TensorFlow Serving for model deployment in production
    items:
    - classname: devsite-landing-row-50
      description: >
        TensorFlow Serving is a flexible, high-performance serving system for
        machine learning models, designed for production environments. TensorFlow
        Serving makes it easy to deploy new algorithms and experiments, while
        keeping the same server architecture and APIs. TensorFlow Serving
        provides out-of-the-box integration with TensorFlow models, but can be
        easily extended to serve other types of models and data.
        
        h3 style='margin-top:1.5em; margin-bottom:0.5em'>Create a production pipeline</h3>
        You can create a production pipeline by adding other components from
        TensorFlow Extended (TFX) to your TensorFlow Serving deployment.  TFX includes
        components that enable your production deployment to monitor and validate your
        data, create engineered features, and analyze your model's results.  Along with
        TensorFlow Serving, TFX also includes:
      list:
      - heading: TensorFlow Data Validation
        description: >
          A library for exploring and validating machine learning data.
        path: /tfx/data_validation
        icon:
          icon_name: chevron_right
          foreground: theme
          background: grey
      - heading: TensorFlow Transform
        description: >
          Perform full-pass analyze phases over data to create transformation
          graphs that are consistently applied during training and serving.
        path: /tfx/transform
        icon:
          icon_name: chevron_right
          foreground: theme
          background: grey
      - heading: TensorFlow Model Analysis
        description: >
          Libraries and visualization components to compute full-pass and sliced
          model metrics over large datasets, and analyze them in a notebook.
        path: /tfx/model_analysis
        icon:
          icon_name: chevron_right
          foreground: theme
          background: grey

      code_block: |
        <pre class="prettyprint lang-bsh">
        # Download the TensorFlow Serving Docker image and repo
        <code class="devsite-terminal">docker pull tensorflow/serving</code><br/>
        <code class="devsite-terminal">git clone https://github.com/tensorflow/serving</code>
        # Location of demo models
        <code class="devsite-terminal">TESTDATA="$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata"</code>

        # Start TensorFlow Serving container and open the REST API port
        <code class="devsite-terminal">docker run -t --rm -p 8501:8501 \
           -v "$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two" \
           -e MODEL_NAME=half_plus_two \
           tensorflow/serving &</code>

        # Query the model using the predict API
        <code class="devsite-terminal">curl -d '{"instances": [1.0, 2.0, 5.0]}' \
           -X POST http://localhost:8501/v1/models/half_plus_two:predict</code><br/>
        # Returns => { "predictions": [2.5, 3.0, 4.5] }
        </pre>

  - classname: devsite-landing-row-cards
    items:
    - heading: "Serving ML Quickly with TensorFlow&nbsp;Serving and Docker"
      image_path: /resources/images/tf-logo-card-16x9.png
      path: https://medium.com/tensorflow/serving-ml-quickly-with-tensorflow-serving-and-docker-7df7094aa008
      buttons:
      - label: Read on TensorFlow blog
        path: https://medium.com/tensorflow/serving-ml-quickly-with-tensorflow-serving-and-docker-7df7094aa008
    - heading: "TensorFlow Serving at the Dev&nbsp;Summit"
      youtube_id: q_IkJcPyNl0
      buttons:
      - label: Watch the video
        path: https://www.youtube.com/watch?v=q_IkJcPyNl0
    - heading: TensorFlow Serving on GitHub
      image_path: /resources/images/github-card-16x9.png
      path: https://github.com/tensorflow/serving
      buttons:
      - label: View on GitHub
        path: https://github.com/tensorflow/serving
