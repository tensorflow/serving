
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../saved_model_warmup/">
      
      
        <link rel="next" href="../tensorboard/">
      
      
      <link rel="icon" href="../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>Performance Guide - Serving</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#performance-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Serving" class="md-header__button md-logo" aria-label="Serving" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Serving
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Performance Guide
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/tensorflow/serving" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Serving Models
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Serving" class="md-nav__button md-logo" aria-label="Serving" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Serving
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/tensorflow/serving" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    Serving Models
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Overview
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Overview
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serving Models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Guide
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow Serving with Docker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/serving_basic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serving a TensorFlow Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/serving_config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensorflow Serving Configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/serving_advanced/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Standard TensorFlow ModelServer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/serving_kubernetes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use TensorFlow Serving with Kubernetes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/custom_servable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Creating a new kind of servable
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/custom_source/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Creating a module that discovers new servable paths
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/custom_op/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serving TensorFlow models with custom ops
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/signature_defs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SignatureDefs in SavedModel for TensorFlow Serving
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../building_with_docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building with docker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../saved_model_warmup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SavedModel Warmup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Performance Guide
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Performance Guide
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Quick Tips
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tuning-objectives-and-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tuning: Objectives and Parameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Tuning: Objectives and Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Objectives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-the-tensorflow-model" class="md-nav__link">
    <span class="md-ellipsis">
      1) The TensorFlow Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-the-inference-requests" class="md-nav__link">
    <span class="md-ellipsis">
      2) The Inference Requests
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2) The Inference Requests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      API Surfaces
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-methods" class="md-nav__link">
    <span class="md-ellipsis">
      API Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-the-server-hardware-binary" class="md-nav__link">
    <span class="md-ellipsis">
      3) The Server (Hardware &amp; Binary)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3) The Server (Hardware & Binary)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#accelerators" class="md-nav__link">
    <span class="md-ellipsis">
      Accelerators
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-cpus" class="md-nav__link">
    <span class="md-ellipsis">
      Modern CPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#life-of-a-tensorflow-serving-inference-request" class="md-nav__link">
    <span class="md-ellipsis">
      Life of a TensorFlow Serving inference request
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Life of a TensorFlow Serving inference request">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequence-diagram" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Diagram
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-details" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Details
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorboard/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profile Inference Requests with TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/api_rest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Client API (REST)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Client API (gRPC)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/tensorflow_serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Server API (C++)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Quick Tips
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tuning-objectives-and-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tuning: Objectives and Parameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Performance Tuning: Objectives and Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Objectives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-the-tensorflow-model" class="md-nav__link">
    <span class="md-ellipsis">
      1) The TensorFlow Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-the-inference-requests" class="md-nav__link">
    <span class="md-ellipsis">
      2) The Inference Requests
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2) The Inference Requests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      API Surfaces
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-methods" class="md-nav__link">
    <span class="md-ellipsis">
      API Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-the-server-hardware-binary" class="md-nav__link">
    <span class="md-ellipsis">
      3) The Server (Hardware &amp; Binary)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3) The Server (Hardware & Binary)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#accelerators" class="md-nav__link">
    <span class="md-ellipsis">
      Accelerators
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-cpus" class="md-nav__link">
    <span class="md-ellipsis">
      Modern CPUs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Configuration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#life-of-a-tensorflow-serving-inference-request" class="md-nav__link">
    <span class="md-ellipsis">
      Life of a TensorFlow Serving inference request
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Life of a TensorFlow Serving inference request">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sequence-diagram" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Diagram
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-details" class="md-nav__link">
    <span class="md-ellipsis">
      Sequence Details
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="performance-guide">Performance Guide<a class="headerlink" href="#performance-guide" title="Permanent link">¶</a></h1>
<p>The performance of TensorFlow Serving is highly dependent on the application it
runs, the environment in which it is deployed and other software with which it
shares access to the underlying hardware resources. As such, tuning its
performance is somewhat case-dependent and there are very few universal rules
that are guaranteed to yield optimal performance in all settings. With that
said, this document aims to capture some general principles and best practices
for running TensorFlow Serving.</p>
<p>Please use the <a href="../tensorboard/">Profile Inference Requests with TensorBoard</a>
guide to understand the underlying behavior of your model's computation on
inference requests, and use this guide to iteratively improve its performance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the following quick tips do not solve your problem, please read the
longer discussion to develop a deep understanding of what affects TensorFlow
Serving's performance.</p>
</div>
<h2 id="quick-tips">Quick Tips<a class="headerlink" href="#quick-tips" title="Permanent link">¶</a></h2>
<ul>
<li>Latency of first request is too high? Enable
    <a href="../saved_model_warmup/">model warmup</a>.</li>
<li>Interested in higher resource utilization or throughput? Configure
    <a href="../../guide/serving_config/#batching-configuration">batching</a></li>
</ul>
<h2 id="performance-tuning-objectives-and-parameters">Performance Tuning: Objectives and Parameters<a class="headerlink" href="#performance-tuning-objectives-and-parameters" title="Permanent link">¶</a></h2>
<p>When fine-tuning TensorFlow Serving's performance, there are usually 2 types of
objectives you may have and 3 groups of parameters to tweak to improve upon
those objectives.</p>
<h3 id="objectives">Objectives<a class="headerlink" href="#objectives" title="Permanent link">¶</a></h3>
<p>TensorFlow Serving is an <em>online serving system</em> for machine-learned models. As
with many other online serving systems, its primary performance objective is to
<em>maximize throughput while keeping tail-latency below certain bounds</em>. Depending
on the details and maturity of your application, you may care more about average
latency than
<a href="https://blog.bramp.net/post/2018/01/16/measuring-percentile-latency/">tail-latency</a>,
but some notion of <strong>latency</strong> and <strong>throughput</strong> are usually the metrics
against which you set performance objectives. Note that we do not discuss
availability in this guide as that is more a function of the deployment
environment.</p>
<h3 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">¶</a></h3>
<p>We can roughly think about 3 groups of parameters whose configuration determines
observed performance: 1) the TensorFlow model 2) the inference requests and 3)
the server (hardware &amp; binary).</p>
<h4 id="1-the-tensorflow-model">1) The TensorFlow Model<a class="headerlink" href="#1-the-tensorflow-model" title="Permanent link">¶</a></h4>
<p>The model defines the computation that TensorFlow Serving will perform upon
receiving each incoming request.</p>
<p>Underneath the hood, TensorFlow Serving uses the TensorFlow runtime to do the
actual inference on your requests. This means the <strong>average latency</strong> of serving
a request with TensorFlow Serving is <em>usually</em> at least that of doing inference
directly with TensorFlow. This means if on a given machine, inference on a
single example takes 2 seconds, and you have a sub-second latency target, you
need to profile inference requests, understand what TensorFlow ops and
sub-graphs of your model contribute most to that latency, and re-design your
model with inference latency as a design constraint in mind.</p>
<p>Please note, while the average latency of performing inference with TensorFlow
Serving is usually not lower than using TensorFlow directly, where TensorFlow
Serving shines is keeping the <strong>tail latency</strong> down for many clients querying
many different models, all while efficiently utilizing the underlying hardware
to maximize throughput.</p>
<h4 id="2-the-inference-requests">2) The Inference Requests<a class="headerlink" href="#2-the-inference-requests" title="Permanent link">¶</a></h4>
<h5 id="api-surfaces">API Surfaces<a class="headerlink" href="#api-surfaces" title="Permanent link">¶</a></h5>
<p>TensorFlow Serving has two API surfaces (HTTP and gRPC), both of which implement
the
<a href="https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/apis/prediction_service.proto#L15">PredictionService API</a>
(with the exception of the HTTP Server not exposing a <code>MultiInference</code>
endpoint). Both API surfaces are highly tuned and add minimal latency but in
practice, the gRPC surface is observed to be slightly more performant.</p>
<h5 id="api-methods">API Methods<a class="headerlink" href="#api-methods" title="Permanent link">¶</a></h5>
<p>In general, it is advised to use the Classify and Regress endpoints as they
accept
<a href="https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/apis/input.proto#L77">tf.Example</a>,
which is a higher-level abstraction; however, in rare cases of large (O(Mb))
structured requests, savvy users may find using PredictRequest and directly
encoding their Protobuf messages into a TensorProto, and skipping the
serialization into and deserialization from tf.Example a source of slight
performance gain.</p>
<h5 id="batch-size">Batch Size<a class="headerlink" href="#batch-size" title="Permanent link">¶</a></h5>
<p>There are two primary ways batching can help your performance. You may configure
your clients to send batched requests to TensorFlow Serving, or you may send
individual requests and configure TensorFlow Serving to wait up to a
predetermined period of time, and perform inference on all requests that arrive
in that period in one batch. Configuring the latter kind of batching allows you
to hit TensorFlow Serving at extremely high QPS, while allowing it to
sub-linearly scale the compute resources needed to keep up. This is further
discussed in the <a href="../../guide/serving_config/#batching-configuration">configuration guide</a>
and the
<a href="https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/batching/README.md">batching README</a>.</p>
<h3 id="3-the-server-hardware-binary">3) The Server (Hardware &amp; Binary)<a class="headerlink" href="#3-the-server-hardware-binary" title="Permanent link">¶</a></h3>
<p>The TensorFlow Serving binary does fairly precise accounting of the hardware
upon which it runs. As such, you should avoid running other compute- or
memory-intensive applications on the same machine, especially ones with dynamic
resource usage.</p>
<p>As with many other types of workloads, TensorFlow Serving is more efficient when
deployed on fewer, larger (more CPU and RAM) machines (i.e. a <code>Deployment</code> with
a lower <code>replicas</code> in Kubernetes terms). This is due to a better potential for
multi-tenant deployment to utilize the hardware and lower fixed costs (RPC
server, TensorFlow runtime, etc.).</p>
<h4 id="accelerators">Accelerators<a class="headerlink" href="#accelerators" title="Permanent link">¶</a></h4>
<p>If your host has access to an accelerator, ensure you have implemented your
model to place dense computations on the accelerator - this should be
automatically done if you have used high-level TensorFlow APIs, but if you have
built custom graphs, or want to pin specific parts of graphs on specific
accelerators, you may need to manually place certain subgraphs on accelerators
(i.e. using <code>with tf.device('/device:GPU:0'): ...</code>).</p>
<h4 id="modern-cpus">Modern CPUs<a class="headerlink" href="#modern-cpus" title="Permanent link">¶</a></h4>
<p>Modern CPUs have continuously extended the x86 instruction set architecture to
improve support for <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a> (Single
Instruction Multiple Data) and other features critical for dense computations
(eg. a multiply and addition in one clock cycle). However, in order to run on
slightly older machines, TensorFlow and TensorFlow Serving are built with the
modest assumption that the newest of these features are not supported by the
host CPU.</p>
<p><code>Your CPU supports instructions that this TensorFlow binary was not compiled to
use: AVX2 FMA</code></p>
<p>If you see this log entry (possibly different extensions than the 2 listed) at
TensorFlow Serving start-up, it means you can rebuild TensorFlow Serving and
target your particular host's platform and enjoy better performance. Building
TensorFlow Serving from source is relatively easy using Docker and is documented
<a href="../building_with_docker/">here</a>.</p>
<h4 id="binary-configuration">Binary Configuration<a class="headerlink" href="#binary-configuration" title="Permanent link">¶</a></h4>
<p>TensorFlow Serving offers a number of configuration knobs that govern its
runtime behavior, mostly set through
<a href="https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/model_servers/main.cc">command-line flags</a>.
Some of these (most notably <code>tensorflow_intra_op_parallelism</code> and
<code>tensorflow_inter_op_parallelism</code>) are passed down to configure the TensorFlow
runtime and are auto-configured, which savvy users may override by doing many
experiments and finding the right configuration for their specific workload and
environment.</p>
<h2 id="life-of-a-tensorflow-serving-inference-request">Life of a TensorFlow Serving inference request<a class="headerlink" href="#life-of-a-tensorflow-serving-inference-request" title="Permanent link">¶</a></h2>
<p>Let's briefly go through the life of a prototypical example of a TensorFlow
Serving inference request to see the journey that a typical request goes
through. For our example, we will dive into a Predict Request being received by
the 2.0.0 TensorFlow Serving gRPC API surface.</p>
<p>Let's first look at a component-level sequence diagram, and then jump into the
code that implements this series of interactions.</p>
<h3 id="sequence-diagram">Sequence Diagram<a class="headerlink" href="#sequence-diagram" title="Permanent link">¶</a></h3>
<!-- Note: sequence-diagram is not supported by GitHub's markdown engine.
To activate internally, uncomment the following block and remove the '|'
characters, which are precluding the dashed arrows from being interpreted
as end-comment tokens.-->

<!--

<style> .rendered-sequence-diagram { max-width: 900px; overflow: auto; }
.rendered-sequence-diagram svg { zoom: 0.70; } </style>

<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>participant Client as C
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>participant Prediction\nService as PS
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>participant TensorFlow Predictor as TP
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>participant Server\nCore as SC
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>participant TensorFlow\nRuntime as TF
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>C-&gt;PS: Predict
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>PS-&gt;TP: Predict
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>TP-&gt;SC: GetServableHandle
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>SC-|-&gt;TP: tensorflow::Session
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>TP-&gt;TF: tensorflow::Session::Run
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>TF-|-&gt;TP: Output Tensors from Session.Run
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>TP-|-&gt;PS: PredictResponse
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>PS-|-&gt;C: PredictResponse
</span></code></pre></div>

-->

<p><img alt="Predict Sequence Diagram" src="../../images/predict_sequence_diagram.png"></p>
<p>Note that Client is a component owned by the user, Prediction Service, Servables
and Server Core are owned by TensorFlow Serving and TensorFlow Runtime is owned
by <a href="https://github.com/tensorflow/tensorflow">Core TensorFlow</a>.</p>
<h3 id="sequence-details">Sequence Details<a class="headerlink" href="#sequence-details" title="Permanent link">¶</a></h3>
<ol>
<li><a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/model_servers/prediction_service_impl.cc#L38"><code>PredictionServiceImpl::Predict</code></a>
    receives the <code>PredictRequest</code></li>
<li>We invoke the
    <a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/servables/tensorflow/predict_impl.cc#L146"><code>TensorflowPredictor::Predict</code></a>,
    propagating the request deadline from the gRPC request (if one was set).</li>
<li>Inside <code>TensorflowPredictor::Predict</code>, we
    <a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/servables/tensorflow/predict_impl.cc#L165">lookup the Servable (model)</a>
    the request is looking to perform inference on, from which we retrieve
    information about the SavedModel and more importantly, a handle to the
    <code>Session</code> object in which the model graph is (possibly partially) loaded.
    This Servable object was created and committed in memory when the model was
    loaded by TensorFlow Serving. We then invoke
    <a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/servables/tensorflow/predict_util.cc#L181">internal::RunPredict</a>
    to carry out the prediction.</li>
<li>In <code>internal::RunPredict</code>, after validating and preprocessing the request,
    we use the <code>Session</code> object to perform the inference using a blocking call
    to
    <a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/servables/tensorflow/predict_util.cc#L209">Session::Run</a>,
    at which point, we enter core TensorFlow's codebase. After the
    <code>Session::Run</code> returns and our <code>outputs</code> tensors have been populated, we
    <a href="https://github.com/tensorflow/serving/blob/b5a11f1e5388c9985a6fc56a58c3421e5f78149f/tensorflow_serving/servables/tensorflow/predict_util.cc#L150">convert</a>
    the outputs to a <code>PredictionResponse</code> and return the result up the call
    stack.</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy", "content.code.select"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>